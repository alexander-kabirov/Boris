{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sample_recombination_NER_refactor.ipynb","provenance":[{"file_id":"1WS2nIuP5PRJ4Cq_ubJCB4RuWpvrwunvi","timestamp":1590911673139},{"file_id":"12fuTG_9lFgsUu8zvI-62sO0tUkws-khw","timestamp":1588162498501}],"collapsed_sections":[],"authorship_tag":"ABX9TyPfzg66KwVDNB4BJy/h0xZ4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dc39cf25bf5b41a488725c11e86185c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b916234fe836413f92d591d02261473b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9e24e074c93647259299be60b680adba","IPY_MODEL_07facf8669784d96944e41ede6f4ae58"]}},"b916234fe836413f92d591d02261473b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e24e074c93647259299be60b680adba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_921bc5ef9de24ed3a35006ac30cce58e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_462eed886a514ffc9d16e9632ad72572"}},"07facf8669784d96944e41ede6f4ae58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1e0a54220fff49a7bc751a46a3077e4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.20MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d581d00b465d46798ae7dbca5498ad24"}},"921bc5ef9de24ed3a35006ac30cce58e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"462eed886a514ffc9d16e9632ad72572":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e0a54220fff49a7bc751a46a3077e4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d581d00b465d46798ae7dbca5498ad24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"w_cGSEbvmseX"},"source":["import random\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C9RCtBws6DWO","colab":{"base_uri":"https://localhost:8080/","height":654,"referenced_widgets":["dc39cf25bf5b41a488725c11e86185c2","b916234fe836413f92d591d02261473b","9e24e074c93647259299be60b680adba","07facf8669784d96944e41ede6f4ae58","921bc5ef9de24ed3a35006ac30cce58e","462eed886a514ffc9d16e9632ad72572","1e0a54220fff49a7bc751a46a3077e4d","d581d00b465d46798ae7dbca5498ad24"]},"executionInfo":{"status":"ok","timestamp":1591905349857,"user_tz":-120,"elapsed":14609,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"dd14bd69-b062-4f83-e649-4eb688a20b37"},"source":["import pandas as pd\n","from random import randint\n","!pip install transformers\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 14.0MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 13.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 42.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=0febeab0d0ddf891fdbe38e70845ed463945e2f26099311ef7e56c9e15333774\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc39cf25bf5b41a488725c11e86185c2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kw5p6awEufW-"},"source":["**Defining the entity (column name/variable) and phrase classes**\n","\n","\n","---\n","\n","\n","Class defines what semantic annotation it generates"]},{"cell_type":"code","metadata":{"id":"oW8wCJjCZM-l"},"source":["# Quick and dirty implementation\n","class column_name:\n","  def __init__(self,name):\n","    self.name = name\n","  def return_dic(self):\n","    return {self.name: self}\n","  def generate(self,source):\n","    #set and return the column name\n","    self.column = source.columns[randint(0, len(source.columns)-1)]\n","    self.value = str(self.column)\n","    return self.value\n","\n","class var:\n","  def __init__(self,name): #paired column object\n","    self.name = name\n","  def attach_column(self,column_name):\n","    self.attached_column = column_name\n","    return self\n","  def attach_return(self,column_name):\n","    self.attached_column = column_name\n","    return {column_name.name: column_name, self.name: self}  \n","  def generate(self, source): #get the source and column name from the paired column object \n","    # get the series by the column name\n","    self.value = str(source[self.attached_column.column].iloc[randint(0, len(source)-1)])\n","    return self.value\n","\n","# ToDo: add components element here (a (list) of component selectors )\n","class recombinator:\n","  def __init__(self,representation,variations,inputs,sources,component_selectors=[]): #representation stays the same, variations contain variables and colums names which are taken from the source \n","    self.representation = representation #fixed\n","    self.variations = variations #list\n","    self.inputs = inputs\n","    self.sources = sources #for each variation several sources are used\n","    self.component_selectors = component_selectors\n","    # generate the dict\n","    self.input_dic = {}\n","    for input in inputs:\n","      if isinstance(input,tuple):\n","        self.input_dic[input[0].name] = input[0]\n","        self.input_dic[input[1].name] = input[1].attach_column(input[0])\n","      else:\n","        self.input_dic[input.name] = input\n","\n","# ToDo: add components feature here \n","  def generate(self, n): #n is the number of cycles within the nested loop\n","    gen_texts = []\n","    for variation in self.variations:\n","      for source in self.sources:\n","          for i in range(n):\n","            #get the components here \n","            # get the length of inputs \n","            inp_n = len(self.inputs)\n","            #for each selector embed components (random # of them):\n","            temp_input_dic = self.input_dic\n","            temp_representation = self.representation\n","            temp_variation = variation\n","            for (selector,anchor,max_repeat) in self.component_selectors:\n","              reps = np.random.randint(0,max_repeat)\n","              for rep in range(reps):\n","                embed_parse = selector.pick(0).get_parse()(inp_n)\n","                embed_text = selector.stored[0].get_text()(inp_n)\n","                temp_input_dic = {**temp_input_dic,**selector.stored[0].inputs(inp_n)}\n","                ins_rep_i = temp_representation.index(anchor)\n","                ins_var_i = temp_variation.index(anchor)\n","                temp_representation = temp_representation[:ins_rep_i] + ' ' + embed_parse + temp_representation[ins_rep_i:]\n","                temp_variation = temp_variation[:ins_var_i] + ' ' + embed_text + temp_variation[ins_var_i:]\n","                inp_n += 1\n","              # > remove anchor\n","              temp_representation = temp_representation.replace(anchor,'')\n","              temp_variation = temp_variation.replace(anchor,'')\n","            #instantiate the variables by calling the generate function\n","            gen_dic = {}\n","            ner_dic = {}\n","            for k in temp_input_dic:\n","              gen_dic[k] = temp_input_dic[k].generate(source)\n","              #tokenize the obtained text\n","              token_list = tokenizer.tokenize(gen_dic[k])\n","              ner_dic[k] = ' '.join([k]*len(token_list)) # replicated the class\n","            variation_text = temp_variation.format(**gen_dic) #nice trick here\n","            ner_text = temp_variation.format(**ner_dic) #embed the replicated ner class\n","            ner_tokens = ner_text.split(' ')\n","            ner_target = []\n","            for token in ner_tokens:\n","              if token in list(temp_input_dic.keys()):\n","                ner_target.append(token)\n","              else:\n","                token_list = tokenizer.tokenize(token)\n","                ner_target = ner_target + ['O']*len(token_list)\n","            #print(tokenizer.tokenize(variation_text),ner_target)\n","            gen_texts.append((variation_text,temp_representation,' '.join(ner_target))) \n","            #ner_list[i_s:i_e+1] = [k]*len(ner_list[i_s:i_e+1]) #REPLACEMENT TRICK     \n","            #representation_text = self.representation.format(**rep_dic)\n","            #ext_ner_list[i+ext_num:i+ext_num] = [ner_list[i]]*(len(split)-1) #INCERTION TRICK\n","    return pd.DataFrame(gen_texts,columns=['text','rep','ner'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dyyF1dzegXEu"},"source":["# add componnets list to recombinator, use * for insertion, set the last var and col indexes by len(inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9cRovGqXLvZ"},"source":["# New class 'components' - allows to embed and combine sentence parts\n","class component:\n","  def __init__(self,parse,text_list,inputs):\n","    self.parse = parse\n","    self.text_list = text_list\n","    self.inputs = inputs\n","\n","  def get_parse(self):\n","    return self.parse\n","  def get_text(self):\n","    return random.choice(self.text_list)\n","\n","class component_selector:\n","  def __init__(self,component_list):\n","    self.component_list = component_list\n","    self.stored = {}\n","  def pick(self,i):\n","    self.stored[i] = random.choice(self.component_list)\n","    return self.stored[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EMuppglzdz2w","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1591905464948,"user_tz":-120,"elapsed":129492,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"76bcf941-3b8e-4418-c28d-264de4ddf0d0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6LOlH8QJeSKv"},"source":["zoo_df= pd.read_csv('/content/drive/My Drive/Datasets/zoo2.csv')\n","zoo3_df = pd.read_csv('/content/drive/My Drive/Datasets/zoo3.csv')\n","avocado_df = pd.read_csv('/content/drive/My Drive/Datasets/avocado.csv')\n","cars_df = pd.read_csv('/content/drive/My Drive/Datasets/cars.csv')\n","wildfires_df = pd.read_csv('/content/drive/My Drive/Datasets/wildfires.csv')\n","bike_df = pd.read_csv('/content/drive/My Drive/Datasets/bike.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6DYFPSjELHC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lzfwiHOS-zoB"},"source":[""]},{"cell_type":"code","metadata":{"id":"O4PtmcS6eHkL"},"source":["# Components \n","# ADD MORE VARIATION HERE! {col_3} being {var_3} / which have {var_2} {col_2} / having {var_2} {col_2}\n","eq_comp = component(parse = lambda i: f'f_eq col_{i+1} var_{i+1}',text_list=[lambda i: f'{{var_{i+1}}} {{col_{i+1}}}',\n","                                                                        lambda i: f'{{col_{i+1}}} is {{var_{i+1}}}',\n","                                                                        lambda i: f'{{col_{i+1}}} is equal to {{var_{i+1}}}',\n","                                                                        lambda i: f'{{col_{i+1}}} being {{var_{i+1}}}',\n","                                                                        lambda i: f'{{col_{i+1}}} being equal {{var_{i+1}}}',\n","                                                                        lambda i: f'having {{var_{i+1}}} {{col_{i+1}}}'],\n","                    inputs = lambda i: var(f'var_{i+1}').attach_return(column_name(f'col_{i+1}'))) #NOTICE the attach_return funtion!\n","cond_components = component_selector([eq_comp])\n","and_eq = component(parse = lambda i: f'f_and {cond_components.pick(0).get_parse()(i)}',\n","                     text_list = [lambda i: f'and {cond_components.stored[0].get_text()(i)}'],\n","                     inputs = lambda i: var(f'var_{i+1}').attach_return(column_name(f'col_{i+1}')))\n","or_eq = component(parse = lambda i: f'f_or {cond_components.pick(0).get_parse()(i)}',\n","                     text_list = [lambda i: f'or {cond_components.stored[0].get_text()(i)}'],\n","                     inputs = lambda i: var(f'var_{i+1}').attach_return(column_name(f'col_{i+1}')))\n","logic_components = component_selector([and_eq,or_eq])\n","### Q: Do we actually want to use 'f_and' here? \n","and_col = component(parse = lambda i: f'f_and col_{i+1}', text_list = [lambda i: f'and {{col_{i+1}}}'], inputs = lambda i: column_name(f'col_{i+1}').return_dic())\n","and_col_selector = component_selector([and_col])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHhUBmVB4bIS","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1591905471638,"user_tz":-120,"elapsed":366,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"dc32056a-422f-47d0-86ca-f31ce21ee78b"},"source":["print(and_col.get_parse()(1))\n","print(and_col.get_text()(1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["f_and col_2\n","and {col_2}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4HuKTBG1_El-","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1591905472681,"user_tz":-120,"elapsed":778,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"8aedf679-6943-4602-d5a1-9cc6949e60fc"},"source":["# always appended to existing condition \n","# the separate AND and OR recombinators are not necessary\n","print(logic_components.pick(0).get_parse()(1))\n","print(logic_components.stored[0].get_text()(1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["f_and f_eq col_2 var_2\n","and {col_2} being {var_2}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xDApQ3BkIn7e"},"source":["# for sample 1 add a variation with several selected attributes\n","# Important! Add the samples where var is set to True(1 or >0 ) by the engine (e.g. Pick the animals which have a tail, which have legs, think about the 'do not' sample )\n","#start s_name = \n","# GET UNIQUE VALUES - what are the priorities for instance \n","#>> Introduce different tokenization in order to split name and numbers? \n","\n","#!!!! HOW MANY THIS AND(OR) THAT COLUMN_NAME ARE THERE? \n","sample0 = recombinator('f_select_unique col_1 df_name',\n","                       ['Which {col_1} are there','What are the {col_1}',\n","                        'What are {col_1}',\n","                        'Name the {col_1}','Name {col_1}','Tell me unique {col_1}',\n","                        'Name unique {col_1}','What are unique {col_1}', 'Name different {col_1}',\n","                        'What are the different {col_1}','What are different {col_1}'],\n","                       [column_name('col_1')], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","sample00 = recombinator('f_length f_select_unique col_1 df_name',\n","                       ['How many {col_1}','What is the number of {col_1}','What is number of {col_1}', 'How many different {col_1}',\n","                        'How many {col_1} are there','How many {col_1} is there', 'Count {col_1}', 'Tell me the number of {col_1}','Tell me number of {col_1}',\n","                        'Count different {col_1}','How many unique {col_1}', 'Count unique {col_1}','Count the different {col_1}', 'Count the unique {col_1}'],\n","                       [column_name('col_1')], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","# >>>>>>> - Add the unique variation with filters as well\n","sample1 = recombinator('f_select col_1 f_filter df_name f_eq col_2 var_2',\n","                       ['Which {col_1} have {var_2} {col_2}','What {col_1} have {var_2} {col_2}',\n","                        'Which {col_1} have {col_2} equal to {var_2}',\n","                        'Name the {col_1} where {col_2} is {var_2}', 'Name the {col_1} which have {var_2} {col_2}',\n","                        'Name the {col_1} with {var_2} {col_2}','Name {col_1} where {col_2} is {var_2}','Name {col_1} with {var_2} {col_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","#>------------COMP TESTING ------------ \n","sample2 = recombinator('f_select col_1 f_filter df_name* f_eq col_2 var_2',\n","                       ['Which {col_1} have {var_2} {col_2}*','What {col_1} have {var_2} {col_2}*',\n","                        'Which {col_1} have {col_2} equal to {var_2}*',\n","                        'Name the {col_1} where {col_2} is {var_2}*', 'Name the {col_1} which have {var_2} {col_2}*',\n","                        'Name the {col_1} with {var_2} {col_2}*','Name {col_1} where {col_2} is {var_2}*','Name {col_1} with {var_2} {col_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","#-------------COMP TESTING -----------> \n","\n","sample3 = recombinator('f_length f_filter df_name f_eq col_2 var_2',\n","                       ['How many {col_1} have {var_2} {col_2}','What is the number of {col_1} having {var_2} {col_2}',\n","                        'What is the number of {col_1} with {col_2} equal to {var_2}',\n","                        'How many {col_1} where {col_2} is {var_2}', 'How many {col_1} which have {var_2} {col_2}',\n","                        'How many {col_1} with {var_2} {col_2}','What is the number of {col_1} where {col_2} is {var_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","\n","sample4 = recombinator('f_length f_filter df_name* f_eq col_2 var_2',\n","                       ['How many {col_1} have {var_2} {col_2}*','What is the number of {col_1} having {var_2} {col_2}*',\n","                        'What is the number of {col_1} with {col_2} equal to {var_2}*',\n","                        'How many {col_1} where {col_2} is {var_2}*', 'How many {col_1} which have {var_2} {col_2}*',\n","                        'How many {col_1} with {var_2} {col_2}*','What is the number of {col_1} where {col_2} is {var_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","\n","\n","sample5 = recombinator('f_length f_filter df_name f_eq col_2 var_2',\n","                       ['How many {var_2} {col_2}', 'What is the number of {var_2} {col_2}'],\n","                       [(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","\n","\n","# here the first and second column_names should be the same, we are not adressing this right now\n","# WHAT IS THE LARGEST PRIORITY - take the largest group\n","sample6 = recombinator('f_select col_1 f_max col_1 f_filter df_name f_eq col_2 var_2',\n","                       ['What is the largest {col_1} with {var_2} {col_2}','What is the largest {col_1} having {var_2} {col_2}',\n","                        'What is the largest {col_1} where {col_2} is equal to {var_2}',\n","                        'What is the largest {col_1} where {col_2} is {var_2}', 'What is the largest {col_1} which have {var_2} {col_2}',\n","                        'Name the largest {col_1} with {var_2} {col_2}','Name the largest {col_1} having {var_2} {col_2}',\n","                        'Name the largest {col_1} where {col_2} is equal to {var_2}',\n","                        'Name the largest {col_1} where {col_2} is {var_2}', 'Name the largest {col_1} which have {var_2} {col_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","sample7 = recombinator('f_select col_1 f_max col_1 f_filter df_name* f_eq col_2 var_2',\n","                       ['What is the largest {col_1} with {var_2} {col_2}*','What is the largest {col_1} having {var_2} {col_2}*',\n","                        'What is the largest {col_1} where {col_2} is equal to {var_2}*',\n","                        'What is the largest {col_1} where {col_2} is {var_2}*', 'What is the largest {col_1} which have {var_2} {col_2}*',\n","                        'Name the largest {col_1} with {var_2} {col_2}*','Name the largest {col_1} having {var_2} {col_2}*',\n","                        'Name the largest {col_1} where {col_2} is equal to {var_2}*',\n","                        'Name the largest {col_1} where {col_2} is {var_2}*', 'Name the largest {col_1} which have {var_2} {col_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","\n","\n","# note the trick with the 'price token', this column doesn't have to exist in a specific dataset, but we map price to the closest option \n","# The words which are not present in the query should be mapped to a word in output vocab, e.g. expensive -> price, sold -> ...\n","# Consider things like 'least valuable' it implies some knowledge, e.g. it contains information which is not directly stated \n","sample9 = recombinator('f_select col_1 f_max price f_filter df_name f_eq col_2 var_2',\n","                       ['What is the most expensive {col_1} with {var_2} {col_2}','What is the most expensive {col_1} having {var_2} {col_2}',\n","                        'What is the most expensive {col_1} where {col_2} is equal to {var_2}',\n","                        'What is the most expensive {col_1} where {col_2} is {var_2}', 'What is the most expensive {col_1} which have {var_2} {col_2}',\n","                        'Name the most expensive {col_1} with {var_2} {col_2}','Name the most expensive {col_1} where {col_2} is {var_2}',\n","                        'Name the most expensive {col_1} where {col_2} is equal to {var_2}', 'Name the most expensive {col_1} which have {var_2} {col_2}',\n","                        'Name the most expensive {col_1} having {var_2} {col_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","sample10 = recombinator('f_select col_1 f_max price f_filter df_name* f_eq col_2 var_2',\n","                       ['What is the most expensive {col_1} with {var_2} {col_2}*','What is the most expensive {col_1} having {var_2} {col_2}*',\n","                        'What is the most expensive {col_1} where {col_2} is equal to {var_2}*',\n","                        'What is the most expensive {col_1} where {col_2} is {var_2}*', 'What is the most expensive {col_1} which have {var_2} {col_2}*',\n","                        'Name the most expensive {col_1} with {var_2} {col_2}*','Name the most expensive {col_1} where {col_2} is {var_2}*',\n","                        'Name the most expensive {col_1} where {col_2} is equal to {var_2}*', 'Name the most expensive {col_1} which have {var_2} {col_2}*',\n","                        'Name the most expensive {col_1} having {var_2} {col_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","\n","\n","sample13 = recombinator('f_select col_1 f_min col_1 f_filter df_name f_eq col_2 var_2',\n","                       ['What is the smallest {col_1} with {var_2} {col_2}','What is the smallest {col_1} having {var_2} {col_2}',\n","                        'What is the smallest {col_1} where {col_2} is equal to {var_2}',\n","                        'What is the smallest {col_1} where {col_2} is {var_2}', 'What is the smallest {col_1} which have {var_2} {col_2}',\n","                        'Name the smallest {col_1} with {var_2} {col_2}','Name the smallest {col_1} having {var_2} {col_2}',\n","                        'Name the smallest {col_1} where {col_2} is equal to {var_2}',\n","                        'Name the smallest {col_1} where {col_2} is {var_2}', 'Name the smallest {col_1} which have {var_2} {col_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","sample14 = recombinator('f_select col_1 f_min col_1 f_filter df_name* f_eq col_2 var_2',\n","                       ['What is the smallest {col_1} with {var_2} {col_2}*','What is the smallest {col_1} having {var_2} {col_2}*',\n","                        'What is the smallest {col_1} where {col_2} is equal to {var_2}*',\n","                        'What is the smallest {col_1} where {col_2} is {var_2}*', 'What is the smallest {col_1} which have {var_2} {col_2}*',\n","                        'Name the smallest {col_1} with {var_2} {col_2}*','Name the smallest {col_1} having {var_2} {col_2}*',\n","                        'Name the smallest {col_1} where {col_2} is equal to {var_2}*',\n","                        'Name the smallest {col_1} where {col_2} is {var_2}*', 'Name the smallest {col_1} which have {var_2} {col_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","\n","\n","# Try out least expensive instead of cheapest as well!  \n","sample16 = recombinator('f_select col_1 f_min price f_filter df_name f_eq col_2 var_2',\n","                       ['What is the cheapest {col_1} with {var_2} {col_2}','What is the most cheapest {col_1} having {var_2} {col_2}',\n","                        'What is the cheapest {col_1} where {col_2} is equal to {var_2}',\n","                        'What is the cheapest {col_1} where {col_2} is {var_2}', 'What is the cheapest {col_1} which have {var_2} {col_2}',\n","                        'Name the cheapest {col_1} with {var_2} {col_2}','Name the cheapest {col_1} where {col_2} is {var_2}',\n","                        'Name the cheapest {col_1} where {col_2} is equal to {var_2}', 'Name the cheapest {col_1} which have {var_2} {col_2}',\n","                        'Name the cheapest {col_1} having {var_2} {col_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","sample17 = recombinator('f_select col_1 f_min price f_filter df_name* f_eq col_2 var_2',\n","                       ['What is the cheapest {col_1} with {var_2} {col_2}*','What is the most cheapest {col_1} having {var_2} {col_2}*',\n","                        'What is the cheapest {col_1} where {col_2} is equal to {var_2}*',\n","                        'What is the cheapest {col_1} where {col_2} is {var_2}*', 'What is the cheapest {col_1} which have {var_2} {col_2}*',\n","                        'Name the cheapest {col_1} with {var_2} {col_2}*','Name the cheapest {col_1} where {col_2} is {var_2}*',\n","                        'Name the cheapest {col_1} where {col_2} is equal to {var_2}*', 'Name the cheapest {col_1} which have {var_2} {col_2}*',\n","                        'Name the cheapest {col_1} having {var_2} {col_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","\n","# f_select,column_name,f_max,'count',f_count,column_name,f_filter,df_name,f_eq,column_name,var\n","# [What] [car brand] [had sold] [the most] [[yellow] [cars]]? - here the name of the column 'color' is not mentioned but it is implied by the meaning of word 'yellow' \n","# What {col_1} has the most {var_2} {col_2} and/or\n","# What {col_1} has the largest number of {var_2} {col_2} and/or\n","# What {col_1} has the most {col_2} being {var_2}\n","# What {col_1} has the most {col_2} equal to {var_2} / the largest number of\n","# What {col_1} has the most entries where {col_2} is {var_2} / the largest number of\n","# What {col_1} has the most entries with {var_2} {col_2}/ the largest number of\n","#>> add samples with group \n","sample19 = recombinator('f_select col_1 f_max count f_count col_1 f_filter df_name f_eq col_2 var_2',\n","                       ['What {col_1} has the most {var_2} {col_2}','What {col_1} has the largest number of {var_2} {col_2}',\n","                        'What {col_1} has the most {col_2} being {var_2}', 'What {col_1} has the largest number of {col_2} being {var_2}',\n","                        'What {col_1} has the most {col_2} equal to {var_2}', 'What {col_1} has the largest number of {col_2} equal to {var_2}',\n","                        'What {col_1} has the most entries where {col_2} is {var_2}','What {col_1} has the largest number of entries where {col_2} is {var_2}',\n","                        'What {col_1} has the most entries with {var_2} {col_2}', 'What {col_1} has the largest number of entries with {var_2} {col_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","sample20 = recombinator('f_select col_1 f_max count f_count col_1 f_filter df_name* f_eq col_2 var_2',\n","                       ['What {col_1} has the most {var_2} {col_2}*','What {col_1} has the largest number of {var_2} {col_2}*',\n","                        'What {col_1} has the most {col_2} being {var_2}*', 'What {col_1} has the largest number of {col_2} being {var_2}*',\n","                        'What {col_1} has the most {col_2} equal to {var_2}*', 'What {col_1} has the largest number of {col_2} equal to {var_2}*',\n","                        'What {col_1} has the most entries where {col_2} is {var_2}*','What {col_1} has the largest number of entries where {col_2} is {var_2}*',\n","                        'What {col_1} has the most entries with {var_2} {col_2}*', 'What {col_1} has the largest number of entries with {var_2} {col_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","\n","\n","# ----------------------\n","sample22 = recombinator('f_select col_1 f_min count f_count col_1 f_filter df_name f_eq col_2 var_2',\n","                       ['What {col_1} has the least {var_2} {col_2}','What {col_1} has the smallest number of {var_2} {col_2}',\n","                        'What {col_1} has the least {col_2} being {var_2}', 'What {col_1} has the smallest number of {col_2} being {var_2}',\n","                        'What {col_1} has the least {col_2} equal to {var_2}', 'What {col_1} has the smallest number of {col_2} equal to {var_2}',\n","                        'What {col_1} has the least entries where {col_2} is {var_2}','What {col_1} has the smallest number of entries where {col_2} is {var_2}',\n","                        'What {col_1} has the least entries with {var_2} {col_2}', 'What {col_1} has the smallest number of entries with {var_2} {col_2}'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","# ----------------------\n","sample23 = recombinator('f_select col_1 f_min count f_count col_1 f_filter df_name* f_eq col_2 var_2',\n","                       ['What {col_1} has the least {var_2} {col_2}*','What {col_1} has the smallest number of {var_2} {col_2}*',\n","                        'What {col_1} has the least {col_2} being {var_2}*', 'What {col_1} has the smallest number of {col_2} being {var_2}*',\n","                        'What {col_1} has the least {col_2} equal to {var_2}*', 'What {col_1} has the smallest number of {col_2} equal to {var_2}*',\n","                        'What {col_1} has the least entries where {col_2} is {var_2}*','What {col_1} has the smallest number of entries where {col_2} is {var_2}*',\n","                        'What {col_1} has the least entries with {var_2} {col_2}*', 'What {col_1} has the smallest number of entries with {var_2} {col_2}*'],\n","                       [column_name('col_1'),(column_name('col_2'),var('var_2'))], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],component_selectors=[(logic_components,'*',5)])\n","\n","#----------------------------------<>--------------------------\n","sample25 = recombinator('f_select col_1 f_max col_1 df_name',\n","                       ['What is the largest {col_1}','Name the largest {col_1}','What is the biggest {col_1}','Name the biggest {col_1}','Tell me the largest {col_1}','Tell me the biggest {col_1}',\n","                        'What {col_1} is the largest','What {col_1} is the biggest'], #replicate this for the cases with filters \n","                       [column_name('col_1')], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","sample26 = recombinator('f_select col_1 f_min col_1 df_name',\n","                       ['What is the smallest {col_1}','Name the smallest {col_1}','Tell me the smallest {col_1}', 'What {col_1} is the smallest'],\n","                       [column_name('col_1')], #objects in a tuple are linked \n","                       [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df])\n","\n","#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> new samples:\n","#sample27 =  Group by and sum X, Sum X by Y\n","#sample28 = Group by and Average (take average, get average)\n","# Group by A,B,C,D and E and show me the group sizes/sizes, sizes of the groups\n","####\n","#>>> Save as a parameter to use later, propose to save files to be able to do some data science from mobile - chat window\n","# 1. Just group by -> bot proposed the options of what to do next\n","# 2. Group by + size \n","# 3. Group by + sum(mean/average etc...) a,b,c... (or get for all numerical columns)\n","#>>>> Important! do we want to detect the dataset name ?!!!\n","\n","sample27 = recombinator('f_group df_name* col_1', #at least one grouping column should be mentioned, otherwise error -> **do we want to detect error cases separately?**\n","                        ['Group by {col_1}*'],\n","                        [column_name('col_1')],\n","                        [zoo_df,zoo3_df,avocado_df,cars_df,wildfires_df,bike_df],\n","                        component_selectors=[(and_col_selector,'*',5)]) \n","\n","# Size/ length of column_name group? poisonous group (non-poisonous != true) \n","#sum a and b\n","#there are som assumptions regarding the order which are printed out to the user \n","#sum a and b devided by c\n","#sum a and b and devide by c \n","#multiply a and b \n","#devide a by b, devide a and b \n","#deduct a from b, subtract a from b, subtract a and b from c, deduct a and b from c\n","#Count each type of, How many items of each type \n","# Sort \n","# filter large/smaller (number or another column)\n","# contains\n","# Plot\n","# Merge files\n","# Ensure Filtering is working\n","# Delete column/row\n","# Raname column in excel \n","# add a new column/row to table \n","# All should run super fast!! - only vectorized code\n","# add education al aspects to teach Python/DS\n","# Save dialog as module and deploy\n","\n","#> 'and', 'or' structures of the arbitrary length\n","#> Complex recombinations\n","#> Approximate column search\n","#> Execution based on the column type\n","#> Inputting column metadata to the model, What animals are poisonous, What animals (animal_name) are poisonous -> spider =1 amd poisonous = 1\n","# -- add a new sample \n","#> When prices in New York were the best (When -> year/time, New York -> state), if New York is not present -> we give 0 results,\n","#> if there is a spiders column -> pick it and filter by poisonous\n","#'f_select col_1 f_filter df_name f_eq col_2 true, ['What {col_1} are {col_2}' #replace true with 1 where applicable\n","\n","#! 'f_select col_1 f_filter df_name f_and f_eq col_1 var_2 f_eq col_2 true, ['What {var_2} are {col_2}' - What spiders (spider=1, or animal_type) are poisonous (non-poisonous: False)\n","#! Filter not-equal to  \n","# What animals (animal_name) are poisonous\n","# column types: bin, num, text (cat)\n","# we need column names and types in the input\n","# if no specific column specified -> select all? or pick the most appropriate? \n","#'f_select col_1 f_filter df_name f_and f_eq col_1 var_2 f_eq col_2 true, ['What are {col_2} {var_2}' What are poisonous (and flying) spiders? \n","#'f_select col_1 f_filter df_name f_and f_eq col_1 var_2 f_eq col_2 true, ['What are {col_2} {col_1}'\n","#> Two stage model where we may check column metadata in between (type and contents):\n","#> Run the entity recognition -> anylize the entities -> input those to the next level, if not present do classification? \n","#> alternative input column names and do 1/0 classification in order to get metadata \n","# Transformer => input econder - column/var names -> input decoder - all column names -> output classification by col_1, col_2 etc. \n","# When column is not matched directly we get the closest column and assume it is a variable \n","# Do not map column names yet, just add 'What animal_name are poisonous' = 'f_select col_1 f_filter df_name f_eq col_2 true,\n","\n","# variable name is created automatically, give a way to name it like 'as *name*'\n","# take real life samples >>> \n","# >>> add the ratio samples as well \n","#Sample:\n","# Difference (substraction)\n","# Group and sum a column \n","# Group and sum / group and size\n","# "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mo5m1Lixc7sC"},"source":["test = sample27.generate(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUh5mAWKp9fo","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591906850816,"user_tz":-120,"elapsed":660,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"0009d6bc-085c-45c3-f903-1153810c0099"},"source":["test.iloc[0].rep #.text; .ner"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'f_group df_name f_and col_2 f_and col_3 f_and col_4 f_and col_5 col_1'"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"BvIoSX0uM0pR"},"source":["def run_recombinators(n,recombinator_list):\n","  output_dfs = []\n","  for recombinator in recombinator_list:\n","    output_dfs.append(recombinator.generate(n))\n","  return pd.concat(output_dfs, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9n-sN47RNZcW"},"source":["df = run_recombinators(3,[sample0,sample00,sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample9,sample10,sample13,sample14,sample16,sample17,sample19,sample20,sample22,sample23,sample25,sample26])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C3RGi9qO5sSG"},"source":["30 for samples_l, 1 for valiation"]},{"cell_type":"code","metadata":{"id":"14tvnV3toFGJ"},"source":["# shuffle the dataframe\n","df = df.sample(frac=1).reset_index(drop=True).reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tekbm7-HoZCK"},"source":["df.to_csv('/content/drive/My Drive/Datasets/validate_ner_ref.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uvqdYmGNsO4","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1590953107625,"user_tz":-120,"elapsed":789,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"77f94840-a93b-4c8f-a92c-4e8728cba074"},"source":["len(df)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3402"]},"metadata":{"tags":[]},"execution_count":121}]},{"cell_type":"code","metadata":{"id":"oBC-0jtp_sGb","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1588366350834,"user_tz":-120,"elapsed":594,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"d89eb53a-476d-4e5a-f15d-95f230913cf8"},"source":["tokenizer.tokenize('How many Unnamed: 0 have Chicago region')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['how', 'many', 'unnamed', ':', '0', 'have', 'chicago', 'region']"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"CYf2JYacrgyW","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"ok","timestamp":1590924595059,"user_tz":-120,"elapsed":1433,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"7a0eda37-088f-4840-e292-2652a9551626"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>rep</th>\n","      <th>ner</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Which toothed are there</td>\n","      <td>f_select_unique col_1 df_name</td>\n","      <td>O col_1 col_1 O O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Which fins are there</td>\n","      <td>f_select_unique col_1 df_name</td>\n","      <td>O col_1 O O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Which catsize are there</td>\n","      <td>f_select_unique col_1 df_name</td>\n","      <td>O col_1 col_1 O O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Which predator are there</td>\n","      <td>f_select_unique col_1 df_name</td>\n","      <td>O col_1 O O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Which backbone are there</td>\n","      <td>f_select_unique col_1 df_name</td>\n","      <td>O col_1 O O</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17005</th>\n","      <td>What feature_6 is the smallest</td>\n","      <td>f_select col_1 f_min col_1 df_name</td>\n","      <td>O col_1 col_1 col_1 O O O</td>\n","    </tr>\n","    <tr>\n","      <th>17006</th>\n","      <td>What engine_has_gas is the smallest</td>\n","      <td>f_select col_1 f_min col_1 df_name</td>\n","      <td>O col_1 col_1 col_1 col_1 col_1 O O O</td>\n","    </tr>\n","    <tr>\n","      <th>17007</th>\n","      <td>What year_produced is the smallest</td>\n","      <td>f_select col_1 f_min col_1 df_name</td>\n","      <td>O col_1 col_1 col_1 O O O</td>\n","    </tr>\n","    <tr>\n","      <th>17008</th>\n","      <td>What location_region is the smallest</td>\n","      <td>f_select col_1 f_min col_1 df_name</td>\n","      <td>O col_1 col_1 col_1 O O O</td>\n","    </tr>\n","    <tr>\n","      <th>17009</th>\n","      <td>What engine_capacity is the smallest</td>\n","      <td>f_select col_1 f_min col_1 df_name</td>\n","      <td>O col_1 col_1 col_1 O O O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17010 rows × 3 columns</p>\n","</div>"],"text/plain":["                                       text  ...                                    ner\n","0                   Which toothed are there  ...                      O col_1 col_1 O O\n","1                      Which fins are there  ...                            O col_1 O O\n","2                   Which catsize are there  ...                      O col_1 col_1 O O\n","3                  Which predator are there  ...                            O col_1 O O\n","4                  Which backbone are there  ...                            O col_1 O O\n","...                                     ...  ...                                    ...\n","17005        What feature_6 is the smallest  ...              O col_1 col_1 col_1 O O O\n","17006   What engine_has_gas is the smallest  ...  O col_1 col_1 col_1 col_1 col_1 O O O\n","17007    What year_produced is the smallest  ...              O col_1 col_1 col_1 O O O\n","17008  What location_region is the smallest  ...              O col_1 col_1 col_1 O O O\n","17009  What engine_capacity is the smallest  ...              O col_1 col_1 col_1 O O O\n","\n","[17010 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"Vp2cXRD8_-cv","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1585849496157,"user_tz":-120,"elapsed":851,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"fc8953e4-ed9b-492b-cd6a-e4640c72b23b"},"source":["pd.concat([test_pd,test_pd], ignore_index=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>rep</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Which aquatic have 0 catsize</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Which domestic have 0 milk</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Which feathers have 3 class_type</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Which Large Bags have 1.16 AveragePrice</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Which year have 2016-01-31 Date</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>Name the Total Bags which have 0.0 XLarge Bags</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>Name the Unnamed: 0 which have 39.38 Large Bags</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>Name the engine_has_gas which have False featu...</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>Name the year_produced which have 1 up_counter</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>Name the feature_9 which have sedan body_type</td>\n","      <td>f_select,column_name,f_filter,df_name,f_eq,col...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                 text                                                rep\n","0                        Which aquatic have 0 catsize  f_select,column_name,f_filter,df_name,f_eq,col...\n","1                          Which domestic have 0 milk  f_select,column_name,f_filter,df_name,f_eq,col...\n","2                    Which feathers have 3 class_type  f_select,column_name,f_filter,df_name,f_eq,col...\n","3             Which Large Bags have 1.16 AveragePrice  f_select,column_name,f_filter,df_name,f_eq,col...\n","4                     Which year have 2016-01-31 Date  f_select,column_name,f_filter,df_name,f_eq,col...\n","..                                                ...                                                ...\n","85     Name the Total Bags which have 0.0 XLarge Bags  f_select,column_name,f_filter,df_name,f_eq,col...\n","86    Name the Unnamed: 0 which have 39.38 Large Bags  f_select,column_name,f_filter,df_name,f_eq,col...\n","87  Name the engine_has_gas which have False featu...  f_select,column_name,f_filter,df_name,f_eq,col...\n","88     Name the year_produced which have 1 up_counter  f_select,column_name,f_filter,df_name,f_eq,col...\n","89      Name the feature_9 which have sedan body_type  f_select,column_name,f_filter,df_name,f_eq,col...\n","\n","[90 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"0PO5yYSy16GG","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1586718772409,"user_tz":-120,"elapsed":870,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"d3bd0efc-853c-42eb-9c41-768a74586ce2"},"source":["['hey','there','hey'].index('hey')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"SDw3hF3Zz21b","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1586724628270,"user_tz":-120,"elapsed":888,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"7616a3a5-4f5f-489f-a085-19eb0c486ad3"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>rep</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Which predator have 0 milk</td>\n","      <td>f_select column_name 1 1 f_filter df_name f_eq...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Which Large Bags have 74597.93 4225</td>\n","      <td>f_select column_name 1 2 f_filter df_name f_eq...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Which manufacturer_name have gasoline engine_type</td>\n","      <td>f_select column_name 1 1 f_filter df_name f_eq...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What milk have 1 aquatic</td>\n","      <td>f_select column_name 1 1 f_filter df_name f_eq...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What Small Bags have BaltimoreWashington region</td>\n","      <td>f_select column_name 1 2 f_filter df_name f_eq...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>670</th>\n","      <td>What 4046 has the least entries with 10769.2 T...</td>\n","      <td>f_select column_name 1 1 f_min count f_count c...</td>\n","    </tr>\n","    <tr>\n","      <th>671</th>\n","      <td>What duration_listed has the least entries wit...</td>\n","      <td>f_select column_name 1 1 f_min count f_count c...</td>\n","    </tr>\n","    <tr>\n","      <th>672</th>\n","      <td>What breathes has the smallest number of entri...</td>\n","      <td>f_select column_name 1 1 f_min count f_count c...</td>\n","    </tr>\n","    <tr>\n","      <th>673</th>\n","      <td>What AveragePrice has the smallest number of e...</td>\n","      <td>f_select column_name 1 1 f_min count f_count c...</td>\n","    </tr>\n","    <tr>\n","      <th>674</th>\n","      <td>What is_exchangeable has the smallest number o...</td>\n","      <td>f_select column_name 1 1 f_min count f_count c...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>675 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  text                                                rep\n","0                           Which predator have 0 milk  f_select column_name 1 1 f_filter df_name f_eq...\n","1                  Which Large Bags have 74597.93 4225  f_select column_name 1 2 f_filter df_name f_eq...\n","2    Which manufacturer_name have gasoline engine_type  f_select column_name 1 1 f_filter df_name f_eq...\n","3                            What milk have 1 aquatic   f_select column_name 1 1 f_filter df_name f_eq...\n","4     What Small Bags have BaltimoreWashington region   f_select column_name 1 2 f_filter df_name f_eq...\n","..                                                 ...                                                ...\n","670  What 4046 has the least entries with 10769.2 T...  f_select column_name 1 1 f_min count f_count c...\n","671  What duration_listed has the least entries wit...  f_select column_name 1 1 f_min count f_count c...\n","672  What breathes has the smallest number of entri...  f_select column_name 1 1 f_min count f_count c...\n","673  What AveragePrice has the smallest number of e...  f_select column_name 1 1 f_min count f_count c...\n","674  What is_exchangeable has the smallest number o...  f_select column_name 1 1 f_min count f_count c...\n","\n","[675 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":140}]},{"cell_type":"code","metadata":{"id":"YtMg6BcvuUPv"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jrExSXq9KGK0"},"source":["tensor_01 = np.random.randint(0,2, (1000,1,100)) #Alternative could be a matrix where each line is multiplied by a different matrix from tensor_02\n","tensor_02 = np.random.randint(0,2, (1000,100,50))\n","# Goal matrix 1000*50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMH1ffgXuRKR","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1590394003056,"user_tz":-120,"elapsed":431,"user":{"displayName":"Semantika labs","photoUrl":"","userId":"07619975397796211651"}},"outputId":"bd3872bc-4d9c-4acb-c7d7-f32e73b698eb"},"source":["np.einsum('ijk,ikv->iv', tensor_01,tensor_02)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[29, 24, 24, ..., 31, 28, 21],\n","       [19, 25, 23, ..., 20, 22, 24],\n","       [23, 25, 22, ..., 20, 30, 29],\n","       ...,\n","       [23, 20, 25, ..., 16, 24, 22],\n","       [28, 26, 27, ..., 21, 28, 25],\n","       [24, 24, 20, ..., 19, 27, 20]])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"izKn4Vc73uk_"},"source":[""],"execution_count":null,"outputs":[]}]}